{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f5174e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89178a50",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc\n",
    "\n",
    "POSTBACKS_PATH = \"/content/drive/MyDrive/TDS/Postbacks.csv\"\n",
    "CLICKS_PATH = \"/content/drive/MyDrive/TDS/Clicks.csv\"\n",
    "SOURCES_PATH = \"/content/drive/MyDrive/TDS/Source.csv\"\n",
    "OFFERS_PATH = \"/content/drive/MyDrive/TDS/Offers.csv\"\n",
    "\n",
    "OUTPUT_SELECTION_HISTORY = \"selection_history.csv\"\n",
    "KPI_MONITORING_PATH = \"kpi_monitoring.csv\"\n",
    "ALERTS_LOG_PATH = \"alerts_log.csv\"\n",
    "\n",
    "\n",
    "print(\"[INFO] Завантаження даних...\")\n",
    "postbacks = pd.read_csv(POSTBACKS_PATH).sample(frac=1, random_state=42)\n",
    "clicks = pd.read_csv(CLICKS_PATH).sample(frac=1, random_state=42)\n",
    "sources = pd.read_csv(SOURCES_PATH)\n",
    "offers = pd.read_csv(OFFERS_PATH)\n",
    "\n",
    "print(f\"[INFO] Rows: postbacks={len(postbacks)}, clicks={len(clicks)}, sources={len(sources)}, offers={len(offers)}\")\n",
    "\n",
    "for df, col in [(clicks, 'click_timestamp'), (postbacks, 'postback_timestamp')]:\n",
    "    if col in df.columns and not np.issubdtype(df[col].dtype, np.datetime64):\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "postbacks = postbacks[postbacks['click_id'].isin(clicks['click_id'])].copy()\n",
    "\n",
    "if 'os_type' in clicks.columns and 'os' not in clicks.columns:\n",
    "    clicks['os'] = clicks['os_type']\n",
    "\n",
    "if 'user_id' in clicks.columns and 'click_number' in clicks.columns:\n",
    "    clicks['unique_key'] = clicks['user_id'].astype(str) + '_' + clicks['click_number'].astype(str)\n",
    "else:\n",
    "    clicks['unique_key'] = clicks['click_id']\n",
    "\n",
    "if 'user_id' in clicks.columns and 'click_timestamp' in clicks.columns:\n",
    "    clicks = clicks.sort_values(['user_id', 'click_timestamp'])\n",
    "    clicks['time_diff'] = clicks.groupby('user_id')['click_timestamp'].diff().dt.total_seconds()\n",
    "    clicks = clicks[clicks['time_diff'].isna() | (clicks['time_diff'] >= 1)].drop('time_diff', axis=1)\n",
    "\n",
    "clicks = clicks.merge(sources, on='source_id', how='left')\n",
    "clicks = clicks.merge(offers, on='offer_id', how='left')\n",
    "\n",
    "epc_df = postbacks.groupby('offer_id')['revenue'].mean().reset_index().rename(columns={'revenue': 'EPC'})\n",
    "clicks = clicks.merge(epc_df, on='offer_id', how='left').fillna({'EPC': 0})\n",
    "baseline_epc = epc_df['EPC'].mean()\n",
    "\n",
    "cr_series = postbacks.groupby('offer_id').size() / clicks.groupby('offer_id').size()\n",
    "cr_df = cr_series.reset_index().rename(columns={0: 'CR'}).fillna(0)\n",
    "clicks = clicks.merge(cr_df, on='offer_id', how='left').fillna({'CR': 0})\n",
    "\n",
    "categorical_cols = ['browser', 'placement', 'device_type', 'geo', 'os', 'network', 'payout_type']\n",
    "encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in clicks.columns:\n",
    "        le = LabelEncoder()\n",
    "        clicks[col] = le.fit_transform(clicks[col].astype(str))\n",
    "        encoders[col] = le\n",
    "\n",
    "\n",
    "if 'remaining_daily_cap' not in offers.columns:\n",
    "    offers['remaining_daily_cap'] = offers['daily_cap_amount'].fillna(1e12)\n",
    "if 'remaining_total_cap' not in offers.columns:\n",
    "    offers['remaining_total_cap'] = offers['total_cap_amount'].fillna(1e12)\n",
    "\n",
    "\n",
    "print(\"[INFO] Тренування RandomForest...\")\n",
    "features = [c for c in ['browser', 'placement', 'device_type', 'geo', 'os', 'network', 'payout_type', 'EPC', 'CR'] if c in clicks.columns]\n",
    "clicks['target'] = clicks['offer_id'].isin(postbacks['offer_id']).astype(int)\n",
    "\n",
    "X = clicks[features]\n",
    "y = clicks['target']\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X, y)\n",
    "print(f\"[INFO] Модель натренована. Позитивних прикладів: {y.sum()}\")\n",
    "gc.collect()\n",
    "\n",
    "epc_window = deque(maxlen=50)\n",
    "cr_window = deque(maxlen=50)\n",
    "ctr_window = deque(maxlen=50)\n",
    "\n",
    "\n",
    "def monitor_kpi(clicks_df, postbacks_df, current_date):\n",
    "    daily_clicks = clicks_df[clicks_df['click_timestamp'].dt.date == current_date]\n",
    "    daily_postbacks = postbacks_df[postbacks_df['postback_timestamp'].dt.date == current_date]\n",
    "\n",
    "    clicks_count = len(daily_clicks)\n",
    "    conversions = len(daily_postbacks)\n",
    "    impressions = clicks_count * 10  # 1 клік = 10 показів\n",
    "    cr = (conversions / clicks_count * 100) if clicks_count > 0 else 0\n",
    "    ctr = (clicks_count / impressions * 100) if impressions > 0 else 0\n",
    "    revenue = daily_postbacks['revenue'].sum()\n",
    "    epc = revenue / clicks_count if clicks_count > 0 else 0\n",
    "\n",
    "    kpi = {\n",
    "        'date': current_date,\n",
    "        'clicks': clicks_count,\n",
    "        'conversions': conversions,\n",
    "        'impressions': impressions,\n",
    "        'cr_percent': cr,\n",
    "        'ctr_percent': ctr,\n",
    "        'epc': epc,\n",
    "        'revenue': revenue\n",
    "    }\n",
    "\n",
    "    # Запис у файл\n",
    "    pd.DataFrame([kpi]).to_csv(KPI_MONITORING_PATH, mode='a', header=not os.path.exists(KPI_MONITORING_PATH), index=False)\n",
    "    print(f\"[KPI] Date: {current_date}, Clicks: {clicks_count}, Impressions: {impressions}, CR: {cr:.2f}%, CTR: {ctr:.2f}%, EPC: {epc:.4f}\")\n",
    "\n",
    "    epc_window.append(epc)\n",
    "    cr_window.append(cr)\n",
    "    ctr_window.append(ctr)\n",
    "\n",
    "    return kpi\n",
    "\n",
    "def check_anomalies(clicks_df, postbacks_df, baseline_epc, current_date):\n",
    "    alerts = []\n",
    "    daily_clicks = clicks_df[clicks_df['click_timestamp'].dt.date == current_date]\n",
    "    daily_postbacks = postbacks_df[postbacks_df['postback_timestamp'].dt.date == current_date]\n",
    "\n",
    "    clicks_per_hour = daily_clicks.groupby(daily_clicks['click_timestamp'].dt.hour).size()\n",
    "    mean_clicks = clicks_per_hour.mean()\n",
    "    std_clicks = clicks_per_hour.std()\n",
    "    threshold = mean_clicks + 3 * std_clicks if std_clicks > 0 else mean_clicks * 2\n",
    "    for hour, count in clicks_per_hour.items():\n",
    "        if count > threshold:\n",
    "            alerts.append({'timestamp': datetime.utcnow(), 'type': 'traffic_spike', 'details': f'Hour {hour}: {count} clicks > {threshold:.0f}'})\n",
    "\n",
    "    clicks_count = len(daily_clicks)\n",
    "    revenue = daily_postbacks['revenue'].sum()\n",
    "    epc = revenue / clicks_count if clicks_count > 0 else 0\n",
    "    if epc < baseline_epc * 0.8 and clicks_count > 100:\n",
    "        alerts.append({'timestamp': datetime.utcnow(), 'type': 'low_epc', 'details': f'EPC {epc:.4f} < {baseline_epc * 0.8:.4f} (-20%)'})\n",
    "\n",
    "    conversions = len(daily_postbacks)\n",
    "    cr = (conversions / clicks_count * 100) if clicks_count > 0 else 0\n",
    "    if cr > 50 and clicks_count > 100:\n",
    "        alerts.append({'timestamp': datetime.utcnow(), 'type': 'high_cr', 'details': f'CR {cr:.2f}% > 50%'})\n",
    "\n",
    "    if 'ip_address' in daily_clicks.columns:\n",
    "        ip_counts = daily_clicks.groupby('ip_address').size()\n",
    "        for ip, count in ip_counts.items():\n",
    "            if count > 100:\n",
    "                alerts.append({'timestamp': datetime.utcnow(), 'type': 'suspicious_ip', 'details': f'IP {ip}: {count} clicks'})\n",
    "\n",
    "    if alerts:\n",
    "        pd.DataFrame(alerts).to_csv(ALERTS_LOG_PATH, mode='a', header=not os.path.exists(ALERTS_LOG_PATH), index=False)\n",
    "        for alert in alerts:\n",
    "            print(f\"[ALERT] {alert['type']}: {alert['details']}\")\n",
    "            if alert['type'] == 'suspicious_ip':\n",
    "                print(f\"[ACTION] Blocking IP: {alert['details'].split(':')[0].split(' ')[1]}\")\n",
    "            elif alert['type'] == 'traffic_spike':\n",
    "                print(\"[ACTION] Investigate traffic source for potential fraud\")\n",
    "            elif alert['type'] in ['low_epc', 'high_cr']:\n",
    "                print(\"[ACTION] Review offer performance and traffic quality\")\n",
    "\n",
    "    return alerts\n",
    "\n",
    "def plot_kpi_history():\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(range(len(epc_window)), epc_window, label='EPC', color='green')\n",
    "    plt.axhline(y=baseline_epc * 0.8, color='red', linestyle='--', label='EPC Alert Threshold (-20%)')\n",
    "    plt.title('EPC (Last 50 clicks)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(range(len(cr_window)), cr_window, label='CR (%)', color='blue')\n",
    "    plt.axhline(y=50, color='red', linestyle='--', label='CR Alert Threshold (50%)')\n",
    "    plt.title('Conversion Rate (CR)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(range(len(ctr_window)), ctr_window, label='CTR (%)', color='orange')\n",
    "    plt.title('Click-Through Rate (CTR)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def update_caps_dynamic(offers_df, clicks_df, postbacks_df, current_date):\n",
    "    offers_df = offers_df.copy()\n",
    "    daily_clicks = clicks_df[clicks_df['click_timestamp'].dt.date == current_date] if not clicks_df.empty else pd.DataFrame()\n",
    "    daily_pbs = postbacks_df[postbacks_df['postback_timestamp'].dt.date == current_date] if not postbacks_df.empty else pd.DataFrame()\n",
    "\n",
    "    ppc_mask = offers_df['payout_type'] == 'PPC'\n",
    "    if ppc_mask.any():\n",
    "        ppc_offer_ids = offers_df.loc[ppc_mask, 'offer_id'].unique()\n",
    "        daily_click_counts = daily_clicks[daily_clicks['offer_id'].isin(ppc_offer_ids)].groupby('offer_id').size() if not daily_clicks.empty else pd.Series()\n",
    "        total_click_counts = clicks_df[clicks_df['offer_id'].isin(ppc_offer_ids)].groupby('offer_id').size() if not clicks_df.empty else pd.Series()\n",
    "        for oid in ppc_offer_ids:\n",
    "            dcount = daily_click_counts.get(oid, 0)\n",
    "            tcount = total_click_counts.get(oid, 0)\n",
    "            daily_cap = offers_df.loc[offers_df['offer_id'] == oid, 'daily_cap_amount'].fillna(1e12).values[0]\n",
    "            total_cap = offers_df.loc[offers_df['offer_id'] == oid, 'total_cap_amount'].fillna(1e12).values[0]\n",
    "            offers_df.loc[offers_df['offer_id'] == oid, 'remaining_daily_cap'] = max(0, daily_cap - dcount)\n",
    "            offers_df.loc[offers_df['offer_id'] == oid, 'remaining_total_cap'] = max(0, total_cap - tcount)\n",
    "\n",
    "    ppl_mask = offers_df['payout_type'].isin(['PPL', 'PPS'])\n",
    "    if ppl_mask.any():\n",
    "        ppl_offer_ids = offers_df.loc[ppl_mask, 'offer_id'].unique()\n",
    "        daily_conv_counts = daily_pbs[daily_pbs['offer_id'].isin(ppl_offer_ids)].groupby('offer_id').size() if not daily_pbs.empty else pd.Series()\n",
    "        total_conv_counts = postbacks_df[postbacks_df['offer_id'].isin(ppl_offer_ids)].groupby('offer_id').size() if not postbacks_df.empty else pd.Series()\n",
    "        for oid in ppl_offer_ids:\n",
    "            dconv = daily_conv_counts.get(oid, 0)\n",
    "            tconv = total_conv_counts.get(oid, 0)\n",
    "            daily_cap = offers_df.loc[offers_df['offer_id'] == oid, 'daily_cap_amount'].fillna(1e12).values[0]\n",
    "            total_cap = offers_df.loc[offers_df['offer_id'] == oid, 'total_cap_amount'].fillna(1e12).values[0]\n",
    "            offers_df.loc[offers_df['offer_id'] == oid, 'remaining_daily_cap'] = max(0, daily_cap - dconv)\n",
    "            offers_df.loc[offers_df['offer_id'] == oid, 'remaining_total_cap'] = max(0, total_cap - tconv)\n",
    "\n",
    "    gc.collect()\n",
    "    return offers_df\n",
    "\n",
    "def choose_offer(click_row, epsilon=0.1, offers_df=offers):\n",
    "    is_split = click_row.get('is_split_offer', 0)\n",
    "    offers_df = update_caps_dynamic(offers_df, clicks, postbacks, click_row['click_timestamp'].date())\n",
    "    if is_split == 0:\n",
    "        possible_offers = offers_df[(offers_df['is_backfill'] == 0) & (offers_df['remaining_daily_cap'] > 0) & (offers_df['remaining_total_cap'] > 0)]\n",
    "    else:\n",
    "        possible_offers = offers_df[(offers_df['remaining_daily_cap'] > 0) & (offers_df['remaining_total_cap'] > 0)]\n",
    "\n",
    "    if possible_offers.empty:\n",
    "        possible_offers = offers_df[(offers_df['is_backfill'] == 1) & (offers_df['remaining_daily_cap'] > 0) & (offers_df['remaining_total_cap'] > 0)]\n",
    "\n",
    "    if possible_offers.empty:\n",
    "        return None, {'reason': 'no_offers'}\n",
    "\n",
    "    possible_offers = possible_offers.copy()\n",
    "    input_data = []\n",
    "    for _, off in possible_offers.iterrows():\n",
    "        row_data = click_row[features].copy()\n",
    "        row_data['EPC'] = epc_df.loc[epc_df['offer_id'] == off['offer_id'], 'EPC'].mean() if off['offer_id'] in epc_df['offer_id'].values else 0\n",
    "        row_data['CR'] = cr_df.loc[cr_df['offer_id'] == off['offer_id'], 'CR'].mean() if off['offer_id'] in cr_df['offer_id'].values else 0\n",
    "        input_data.append(row_data)\n",
    "\n",
    "    input_df = pd.DataFrame(input_data, columns=features)\n",
    "    preds = model.predict_proba(input_df)[:, 1]\n",
    "    possible_offers['score'] = preds\n",
    "\n",
    "    if np.random.rand() > epsilon:\n",
    "        best_offer = possible_offers.loc[possible_offers['score'].idxmax()]\n",
    "    else:\n",
    "        top3 = possible_offers.nlargest(3, 'score')\n",
    "        best_offer = top3.sample(1).iloc[0]\n",
    "\n",
    "    selected_offer_id = best_offer['offer_id']\n",
    "\n",
    "    idx_offer = offers.index[offers['offer_id'] == selected_offer_id]\n",
    "    if not idx_offer.empty:\n",
    "        idx_offer = idx_offer[0]\n",
    "        if best_offer['payout_type'] == 'PPC':\n",
    "            offers.at[idx_offer, 'remaining_daily_cap'] = max(0, offers.at[idx_offer, 'remaining_daily_cap'] - 1)\n",
    "            offers.at[idx_offer, 'remaining_total_cap'] = max(0, offers.at[idx_offer, 'remaining_total_cap'] - 1)\n",
    "        else:\n",
    "            had_pb = (postbacks['click_id'] == click_row['click_id']).any()\n",
    "            if had_pb:\n",
    "                offers.at[idx_offer, 'remaining_daily_cap'] = max(0, offers.at[idx_offer, 'remaining_daily_cap'] - 1)\n",
    "                offers.at[idx_offer, 'remaining_total_cap'] = max(0, offers.at[idx_offer, 'remaining_total_cap'] - 1)\n",
    "\n",
    "    info = {\n",
    "        'pool_type': 'prioritized' if is_split == 0 else 'active' if not possible_offers['is_backfill'].all() else 'backfill',\n",
    "        'score': best_offer['score'],\n",
    "        'epsilon': epsilon\n",
    "    }\n",
    "    rec = {\n",
    "        'timestamp': datetime.utcnow(),\n",
    "        'click_id': click_row['click_id'],\n",
    "        'assigned_offer': selected_offer_id,\n",
    "        'pool_type': info['pool_type'],\n",
    "        'score': info['score']\n",
    "    }\n",
    "    pd.DataFrame([rec]).to_csv(OUTPUT_SELECTION_HISTORY, mode='a', header=not os.path.exists(OUTPUT_SELECTION_HISTORY), index=False)\n",
    "\n",
    "    return selected_offer_id, info\n",
    "\n",
    "def run_simulation(sample_size=1, epsilon=0.1):\n",
    "    sampled_clicks = clicks.sample(sample_size, random_state=42).reset_index(drop=True)\n",
    "    current_date = datetime(year=2024, month=10, day=17).date()\n",
    "\n",
    "    for i, click_row in sampled_clicks.iterrows():\n",
    "        chosen_offer, info = choose_offer(click_row, epsilon)\n",
    "\n",
    "        monitor_kpi(clicks, postbacks, current_date)\n",
    "        check_anomalies(clicks, postbacks, baseline_epc, current_date)\n",
    "\n",
    "    plot_kpi_history()\n",
    "\n",
    "run_simulation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c766ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(sample_size=1, epsilon=0.1):\n",
    "    sampled_clicks = clicks.sample(sample_size, random_state=42).reset_index(drop=True)\n",
    "    current_date = datetime(year=2024, month=10, day=17).date()\n",
    "\n",
    "    for i, click_row in sampled_clicks.iterrows():\n",
    "        chosen_offer, info = choose_offer(click_row, epsilon)\n",
    "\n",
    "        print(click_row,chosen_offer, info)\n",
    "\n",
    "run_simulation()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
